import os
import tempfile
import requests
from flask import Flask, render_template, request, redirect, url_for, jsonify
from werkzeug.utils import secure_filename
from dotenv import load_dotenv

# Load env vars
load_dotenv()

PROJECT_ID = os.getenv("PROJECT_ID")
GOOGLE_CLOUD_LOCATION = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
COURTLISTENER_TOKEN = os.getenv("COURTLISTENER_TOKEN")
GOOGLE_APPLICATION_CREDENTIALS = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

# PDF upload settings
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = tempfile.gettempdir()
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50 MB
ALLOWED_EXTENSIONS = {'pdf'}

def allowed_file(filename: str) -> bool:
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# ------------------------------
# Vertex AI / Gemini setup
# ------------------------------
from google import genai
from google.genai.types import HttpOptions

client = genai.Client(
    vertexai=True,
    project=PROJECT_ID,
    location=GOOGLE_CLOUD_LOCATION,
    http_options=HttpOptions(api_version="v1")
)

def call_genai(prompt: str, max_output_tokens: int = 256) -> str:
    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
        )
        return response.text
    except Exception as e:
        return f"[Gemini API error: {e}]"

# ------------------------------
# CourtListener search (v4) - REPLACED
# ------------------------------
def query_courtlistener(q: str, page_size: int = 10):
    """
    Query CourtListener v4 search endpoint and return a list of simplified case dicts.
    Uses the v4 endpoint and maps fields to: id, title, citation, pdf_link, snippet, court, decision_date.
    """
    base = "https://www.courtlistener.com/api/rest/v4/search/"
    params = {
        "q": q,
        "page_size": page_size,
    }
    headers = {}
    if COURTLISTENER_TOKEN:
        headers["Authorization"] = f"Token {COURTLISTENER_TOKEN}"

    resp = requests.get(base, params=params, headers=headers, timeout=20)
    resp.raise_for_status()
    data = resp.json()

    results = []
    for item in data.get("results", []):
        # safe extraction with multiple fallbacks
        title = item.get("caseName") or item.get("name") or item.get("title") or "Untitled"
        citation = item.get("citation") or ""
        # CourtListener often returns absolute_url (path), html_url, or other link fields
        pdf_link = item.get("absolute_url") or item.get("html_url") or item.get("url") or ""
        snippet = item.get("snippet") or item.get("summary") or item.get("lead_paragraph") or ""
        court = item.get("court") or {}
        decision_date = item.get("decision_date") or item.get("date") or item.get("decision_date_display") or ""

        results.append({
            "id": item.get("id"),
            "title": title,
            "citation": citation,
            "pdf_link": pdf_link,
            "snippet": snippet,
            "court": court,
            "decision_date": decision_date
        })
    return results

# ------------------------------
# PDF extraction (placeholder)
# ------------------------------
def extract_pdf_text(path: str) -> str:
    return f"[Mock extracted text from {os.path.basename(path)}]"

# ------------------------------
# Routes
# ------------------------------
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload():
    if 'pdf' not in request.files:
        return redirect(url_for('index'))
    file = request.files['pdf']
    if file.filename == '':
        return redirect(url_for('index'))
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        extracted_text = extract_pdf_text(filepath)
        return jsonify({'filename': filename, 'text': extracted_text})
    return redirect(url_for('index'))

@app.route('/chat', methods=['POST'])
def chat():
    """
    Improved chat endpoint:
    - Ask clarifying questions (as before).
    - Proceed to retrieval when clarified OR clarification_answers present OR clarify_attempts >= 2.
    - Return top-10 CourtListener results plus 1-2 sentence rationale for each (generated by LLM).
    """

    payload = request.json or {}
    user_input = payload.get("message", "").strip()
    clarified = bool(payload.get("clarified", False))
    clarification_answers = payload.get("clarification_answers", None)  # list or string
    try:
        clarify_attempts = int(payload.get("clarify_attempts", 0))
    except Exception:
        clarify_attempts = 0

    # If we don't yet have clarifications, generate clarifying questions (max 2 rounds)
    if (not clarified) and (not clarification_answers) and (clarify_attempts < 2):
        # Ask GenAI (Gemini) to produce short clarifying questions
        q_text = call_genai(
            f"You are a legal assistant. Given the user's input: \"{user_input}\", "
            "ask 3 or less brief clarifying questions (jurisdiction, main legal issue, key facts). "
            "Return each question on its own line."
        )
        clarify_attempts += 1
        

        questions = [q.strip() for q in q_text.splitlines() if q.strip()]
        if not questions:
            questions = [q_text]

        # Tell the frontend how many attempts we've made (frontend should send back clarify_attempts+1)
        return jsonify({
            "status": "clarifying",
            "questions": questions,
            "raw": q_text,
            "clarify_attempts": clarify_attempts + 1
        })

    # Otherwise proceed to retrieval (either clarified=True, clarification_answers present, or attempts exhausted)
    query_pieces = []
    if user_input:
        query_pieces.append(user_input)
    if clarification_answers:
        if isinstance(clarification_answers, list):
            query_pieces.extend([str(a) for a in clarification_answers if a and str(a).strip()])
        else:
            if str(clarification_answers).strip():
                query_pieces.append(str(clarification_answers))

    query_str = " ".join(query_pieces).strip()
    if not query_str:
        # Safety fallback to avoid empty queries
        query_str = user_input or "legal precedent"

    # Perform CourtListener v4 search (top 10)
    try:
        cases = query_courtlistener(query_str, page_size=10)
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"Error querying CourtListener: {e}"
        }), 500

    # Rationale generation helper (best-effort; won't crash main flow)
    def call_genai_rationale_for_case(query_text: str, case_title: str, snippet: str) -> str:
        prompt = (
            "You are a concise legal research assistant. Given the user's query: "
            f"'{query_text}', and the following case title and snippet: '{case_title} - {snippet}',\n"
            "write a 1-2 sentence explanation why this case might be relevant (focus on legal issue similarity, factual similarity, and jurisdiction authority)."
        )
        try:
            return call_genai(prompt, max_output_tokens=120)
        except Exception:
            return "LLM unavailable to generate rationale."

    # Generate rationales (best-effort; if GenAI fails we still return results)
    rationales = []
    for c in cases:
        snippet = c.get("snippet") or c.get("title") or ""
        rationale = call_genai_rationale_for_case(query_str, c.get("title", ""), snippet)
        rationales.append(rationale)

    # Attach rationale to each case and prepare return
    for idx, c in enumerate(cases):
        c["relevance"] = rationales[idx] if idx < len(rationales) else ""

    return jsonify({
        "status": "results",
        "query": query_str,
        "cases": cases
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
